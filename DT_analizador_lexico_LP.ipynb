{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DT_analizador_lexico_LP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "qMG6L8FpP53E",
        "outputId": "c5740159-baba-4cee-d36c-afc5d9e4a904"
      },
      "source": [
        "#Diccionario usado para el metodo toStrig de un objeto Token\n",
        "diccionario_simbolos = {\n",
        "  '+':\"tk_mas\",\n",
        "  '-':\"tk_menos\",\n",
        "  '*':\"tk_mult\",\n",
        "  '/':\"tk_div\",\n",
        "  '%':\"tk_mod\",\n",
        "  '=':\"tk_asig\",\n",
        "  '<':\"tk_menor\",\n",
        "  '>':\"tk_mayor\",\n",
        "  '<=': \"tk_menor_igual\",\n",
        "  '>=':\"tk_mayor_igual\",\n",
        "  '==': \"tk_igual\",\n",
        "  '&&':\"tk_y\",\n",
        "  '||':\"tk_o\",\n",
        "  '!=':\"tk_dif\",\n",
        "  '!':\"tk_neg\",\n",
        "  ':':\"tk_dosp\",\n",
        "  ';':\"tk_pyc\",\n",
        "  ',':\"tk_coma\",\n",
        "  '.':\"tk_punto\",\n",
        "  '(':\"tk_par_izq\",\n",
        "  ')':\"tk_par_der\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Lista de palabras reservadas del lenguaje para redoulucin implicita respecto a id's\n",
        "palabras_reservadas = (\"funcion_principal\", \"fin_principal\", \n",
        "                        \"booleano\", \"caracter\", \"entero\", \"real\", \"cadena\",\n",
        "                        \"verdadero\",\"falso\", \n",
        "                        \"leer\", \"imprimir\",\n",
        "                        \"si\",\"entonces\", \"si_no\", \"fin_si\",\n",
        "                        \"mientras\", \"hacer\", \"fin_mientras\",\n",
        "                        \"para\", \"fin_para\",\n",
        "                        \"seleccionar\", \"entre\", \"caso\", \"romper\", \"defecto\", \"fin_seleccionar\",\n",
        "                        \"estructura\", \"fin_estructura\",\n",
        "                        \"funcion\", \"retornar\", \"fin_funcion\")\n",
        "\n",
        "\n",
        "#funcion para revisar si una palabra es palabra reservada del lenguaje\n",
        "def es_palabra_reservada(token):\n",
        "  if(token in palabras_reservadas):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_______________________________________________________________________________________________________\n",
        "#Clase Token\n",
        "class Token(object):\n",
        "\n",
        "  #Constructor de la clase \n",
        "  def __init__(self, fila, columna, lexema, tipo): \n",
        "        self.__dict__.update(fila=fila, columna=columna, lexema=lexema, tipo=tipo) \n",
        "\n",
        "    \n",
        "  #Metodo to String que ayuda a imprimir cada token como se pide en el problema\n",
        "  def __str__(self):\n",
        "  \n",
        "    if (self.tipo in [12]):#ID'S\n",
        "      if (es_palabra_reservada(self.lexema)):\n",
        "        #<palabra_reservada,lÃ­nea,columna>\n",
        "        pr = \"<\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "        return pr\n",
        "      else:\n",
        "        #<id,lexema,fila,columna>\n",
        "        pr = \"<id,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "        return pr\n",
        "    elif (self.tipo in [2,6]):\n",
        "      #<tk_entero,lexema,fila,columna>\n",
        "      pr = \"<tk_entero,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [5]):\n",
        "      #<tk_real,lexema,fila,columna>\n",
        "      pr = \"<tk_real,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [23]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      pr = \"<tk_caracter,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [32]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      pr = \"<tk_cadena,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [41,51,71,882,83,92,93,102,103,202,302,402,403,501,601,701,801,901,1001,2002,3001, 64,82]):#Simbolos-operadores\n",
        "      #<token,fila,columna>\n",
        "      pr = \"<\"+ diccionario_simbolos[self.lexema] +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    else:\n",
        "      return f'Lexema:[{self.lexema}] Fila: {self.fila} Columna: {self.columna} Tipo: {self.tipo}'\n",
        "#_______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_______________________________________________________________________________________________________\n",
        "#Listas utiles\n",
        "digitos = ['0','1','2','3','4','5','6','7','8','9']\n",
        "letras = ['a','e', 'i', 'o', 'u', 'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n",
        "LETRAS = ['A','E', 'I', 'O', 'U', 'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z']\n",
        "caracteres = digitos + letras + LETRAS +[' ','_','\\n']\n",
        "caracteres_permitidos_ids = digitos + letras + LETRAS +['_']\n",
        "alfabeto = letras + LETRAS\n",
        "estados_de_aceptacion = [2,5,6,12,23,32,41,51,71,82,83,92,93,102,103,202,302,402,403,501,601,701,801,901,1001,2002,65,67,64,3001]\n",
        "\n",
        "#variables para verificar que no aparezcan comillassimples o dobles sin cierre\n",
        "comillas_simples_cerradas = 0 \n",
        "comillas_dobles_cerradas = 0\n",
        "#_______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_________________________________________________________________________________\n",
        "#Funcion de trancision asociada al DT para analisis lexico\n",
        "def Funcion_de_transicion(estado, caracter_leido):\n",
        "  global lexema_actual\n",
        "  global comillas_simples_cerradas\n",
        "  global comillas_dobles_cerradas\n",
        "\n",
        "  if (estado==0):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 1\n",
        "    elif (caracter_leido in alfabeto): #Toda variable inicia por letra\n",
        "      return 11\n",
        "    elif (caracter_leido == \"'\"):\n",
        "      comillas_simples_cerradas += 1\n",
        "      return 21\n",
        "    elif (caracter_leido == '\"'):\n",
        "      comillas_dobles_cerradas += 1\n",
        "      return 31\n",
        "    elif (caracter_leido == \"+\"):\n",
        "      return 41\n",
        "    elif (caracter_leido == \"-\"):\n",
        "      return 51\n",
        "    elif (caracter_leido == \"/\"):\n",
        "      return 61\n",
        "    elif (caracter_leido == \"%\"):\n",
        "      return 71\n",
        "    elif (caracter_leido == \"=\"):\n",
        "      return 81\n",
        "    elif (caracter_leido == \"<\"):\n",
        "      return 91\n",
        "    elif (caracter_leido == \">\"):\n",
        "      return 101\n",
        "    elif (caracter_leido == \"&\"):\n",
        "      return 201\n",
        "    elif (caracter_leido == \"|\"):\n",
        "      return 301\n",
        "    elif (caracter_leido == \"!\"):\n",
        "      return 401\n",
        "    elif (caracter_leido == \":\"):\n",
        "      return 501\n",
        "    elif (caracter_leido == \";\"):\n",
        "      return 601\n",
        "    elif (caracter_leido == \",\"):\n",
        "      return 701\n",
        "    elif (caracter_leido == \".\"):\n",
        "      return 801\n",
        "    elif (caracter_leido == \"(\"):\n",
        "      return 901\n",
        "    elif (caracter_leido == \")\"):\n",
        "      return 1001\n",
        "    elif (caracter_leido == \"*\"):\n",
        "      return 3001\n",
        "    elif (caracter_leido in [' ', '\\n', '\\r', '\\t'] ):\n",
        "      lexema_actual.pop(-1)\n",
        "      return 0\n",
        "\n",
        "\n",
        "\n",
        "  if (estado==1):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 1\n",
        "    elif (caracter_leido == '.'):\n",
        "      return 3\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 2\n",
        "\n",
        "  if (estado==2):\n",
        "    #devolver_buffer()\n",
        "    #print(\"estado 2 devolvio buffer\",i)\n",
        "    return 0\n",
        "\n",
        "  if (estado==3):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 4\n",
        "    else:\n",
        "      devolver_buffer_2()\n",
        "      return 6\n",
        "\n",
        "  if (estado==4):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 4\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 5\n",
        "\n",
        "  if (estado==5):\n",
        "    return 0\n",
        "\n",
        "  if (estado==6):\n",
        "    return 0\n",
        "\n",
        "  #ID's\n",
        "  if (estado==11):\n",
        "    if (caracter_leido in caracteres_permitidos_ids):\n",
        "      return 11\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 12\n",
        "\n",
        "  if (estado==12):\n",
        "    return 0\n",
        "\n",
        "  #CARACTER\n",
        "  if (estado==21):\n",
        "    if (caracter_leido in caracteres):\n",
        "      return 22\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==22):\n",
        "    if (caracter_leido == \"'\"):\n",
        "      comillas_simples_cerradas -= 1\n",
        "      return 23\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==23):\n",
        "    return 0\n",
        "\n",
        "\n",
        "  #CADENA\n",
        "  if (estado==31):\n",
        "    if (caracter_leido in caracteres):\n",
        "      return 31\n",
        "    if (caracter_leido == '\"'):\n",
        "      comillas_dobles_cerradas -= 1\n",
        "      return 32\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==32):\n",
        "    return 0\n",
        "\n",
        "  # +\n",
        "  if (estado==41):\n",
        "    return 0\n",
        "\n",
        "  # -\n",
        "  if (estado==51):\n",
        "    return 0\n",
        "\n",
        "  # %\n",
        "  if (estado==71):\n",
        "    return 0\n",
        "\n",
        "  # =\n",
        "  if (estado==81):\n",
        "    if (caracter_leido == '='):\n",
        "      return 82\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 83\n",
        "  \n",
        "  # < y <=\n",
        "  if (estado==91):\n",
        "    if (caracter_leido == '='):\n",
        "      return 92\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 93\n",
        "\n",
        "  # > y >=\n",
        "  if (estado==101):\n",
        "    if (caracter_leido == '='):\n",
        "      return 102\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 103\n",
        "\n",
        "  # &&\n",
        "  if (estado==201):\n",
        "    if (caracter_leido == '&'):\n",
        "      return 202\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  # ||\n",
        "  if (estado==301):\n",
        "    if (caracter_leido == '|'):\n",
        "      return 302\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  # !=\n",
        "  if (estado==401):\n",
        "    if (caracter_leido == '='):\n",
        "      return 402\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 403\n",
        "  \n",
        "\n",
        "  #Demas simbolos\n",
        "  if (estado in [501,601,701,801,901,1001,3001,202,302,402]):\n",
        "    return 0\n",
        "\n",
        "  # / --> comentarios y division\n",
        "  if (estado==61):\n",
        "    if (caracter_leido == '/'):\n",
        "      return 62\n",
        "    elif (caracter_leido == '*'):\n",
        "      return 63\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 64\n",
        "\n",
        "  \n",
        "  # // comentario una linea\n",
        "  if (estado==62):\n",
        "    if (caracter_leido != '\\n'):\n",
        "      return 62\n",
        "    else:\n",
        "      return 65\n",
        "\n",
        "\n",
        "  # /* comentario multilinea\n",
        "  if (estado==63):\n",
        "    if (caracter_leido != '*'):\n",
        "      return 63\n",
        "    else:\n",
        "      return 66\n",
        "\n",
        "  \n",
        "  if (estado==66):\n",
        "    if (caracter_leido != '/'):\n",
        "      return 63\n",
        "    else:\n",
        "      return 67\n",
        "\n",
        "  if (estado in [65,67,64]):\n",
        "    return 0\n",
        "\n",
        "  return -1\n",
        "#_________________________________________________________________________________\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "  \n",
        "#_________________________________________________________________________\n",
        "#buffer donde van poniendose simbolos a se analizados\n",
        "buffer = []\n",
        "\n",
        "\n",
        "#variables para llevar la posicion y guardar lugar de iniio de tokens\n",
        "fila_actual = 1\n",
        "columna_actual = 1\n",
        "\n",
        "fila_token_actual = 1\n",
        "columna_token_actual =1\n",
        "\n",
        "estado = 0\n",
        "regreso_realizado = False\n",
        "#_________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_____________________________\n",
        "#Obtener y unificar input\n",
        "import sys\n",
        "T =\"\"\n",
        "for line in sys.stdin:\n",
        "  T += line\n",
        "\n",
        "\n",
        "#algunos tokens requieren leer un caracter adelante. Se agrega un espacio\n",
        "#para que esto siempre sea posible\n",
        "#las cadenas y carcteres no requieren esto\n",
        "l = len(T)\n",
        "if (l>=1 and not (T[-1] in (\"'\",'\"')) and (l>=2 and not (T[-2] in (\"'\",'\"')))):\n",
        "  T += \" \"\n",
        "\n",
        "\n",
        "#string para el outut\n",
        "solucion = \"\"\n",
        "#_____________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#____________________________________________\n",
        "#pila para llevar el lexema actual\n",
        "lexema_actual = [] \n",
        "l = len(T)\n",
        "\n",
        "#funcion para obtener string del lexema\n",
        "def obtener_lexema(s):\n",
        "  respuesta = \"\"\n",
        "  for i in s:\n",
        "    respuesta += str(i)\n",
        "  return respuesta\n",
        "#____________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#____________________________________________\n",
        "#Metodos para devolver el buffer n estados\n",
        "#con sus respectivos ajustes\n",
        "\n",
        "i = 0\n",
        "Lista_posiciones = []\n",
        "\n",
        "def devolver_buffer_1():\n",
        "  global regreso_realizado\n",
        "  regreso_realizado = True\n",
        "  #print(\"buffer atras 1\")\n",
        "  global i \n",
        "  i = i-1\n",
        "  global lexema_actual\n",
        "  lexema_actual.pop(-1)\n",
        "  Lista_posiciones.pop(-1)\n",
        "  posicion = Lista_posiciones[-1]\n",
        "  fila_actual = posicion[0]\n",
        "  columna_actual = posicion[1]\n",
        "\n",
        "def devolver_buffer_2():\n",
        "  global regreso_realizado\n",
        "  regreso_realizado = True\n",
        "  #print(\"buffer atras 2\")\n",
        "  global i \n",
        "  i = i-2\n",
        "  global lexema_actual\n",
        "  lexema_actual.pop(-1)\n",
        "  lexema_actual.pop(-1)\n",
        "  global fila_actual\n",
        "  global columna_actual\n",
        "  Lista_posiciones.pop(-1)\n",
        "  Lista_posiciones.pop(-1)\n",
        "  posicion = Lista_posiciones[-1]\n",
        "  fila_actual = posicion[0]\n",
        "  columna_actual = posicion[1]\n",
        "#____________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "buffer.append(T[0])\n",
        "while (len(buffer) > 0):\n",
        "\n",
        "\n",
        "  #inicio de un token\n",
        "  if (lexema_actual == []):\n",
        "    fila_token_actual = fila_actual\n",
        "    columna_token_actual = columna_actual\n",
        "\n",
        "\n",
        "  #leer caracter\n",
        "  caracter_leido = buffer.pop(0)\n",
        "  lexema_actual += caracter_leido\n",
        "  #Guardar posicion por si mas adelante hay retorno del buffer\n",
        "  posicion_actual = [[fila_actual, columna_actual]]\n",
        "  Lista_posiciones += posicion_actual\n",
        "  \n",
        "\n",
        "  #cambiar de estado\n",
        "  regreso_realizado = False\n",
        "  estado = Funcion_de_transicion(estado, caracter_leido)\n",
        "  if (estado == -1):\n",
        "    solucion += (\">>> Error lexico (linea: \"+str(fila_actual)+\", posicion: \"+str(columna_actual)+\")\"+\"\\n\")\n",
        "    break\n",
        "\n",
        "\n",
        "\n",
        "  #Si se llego a un estado de aceptacion guardar el token hallado. Los estados de comentarios se ignoran.\n",
        "  if (estado in estados_de_aceptacion):\n",
        "    Token_actual_objeto = Token(fila_token_actual, columna_token_actual, obtener_lexema(lexema_actual), estado )\n",
        "    if (estado not in [67,65]):\n",
        "      solucion += (str(Token_actual_objeto) + \"\\n\")\n",
        "    lexema_actual = [] #reiniciar lexema\n",
        "    estado = 0 #Transicion lambda al estado 0 \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Obtener siguiente caracter a usar en el DT\n",
        "  #En caso de haberse dado retorno del buffer, la i fue ajustada en las funciones buffer\n",
        "  i += 1\n",
        "  if (i<l):\n",
        "    buffer.append(T[i])\n",
        "\n",
        "  #Actualizar fila y columna del siguiente caracter a leer\n",
        "  #En caso de haberse dado retorno del buffer, la posicion fue ajustada en las funciones buffer\n",
        "  if (not (regreso_realizado)):\n",
        "    if (caracter_leido==\"\\n\"):\n",
        "      fila_actual +=1\n",
        "      columna_actual = 1\n",
        "    else:\n",
        "      columna_actual +=1  \n",
        "\n",
        "#Si se hallo comilla simple o doble sin cierre y no existe un error lexico antes generar error\n",
        "#Esta situacion solo hace referencia al final de la entrada porque el DT se ocupa de los demas casos adecuadamente\n",
        "if ((comillas_dobles_cerradas + comillas_simples_cerradas) != 0  and estado != -1):\n",
        "  solucion += (\">>> Error lexico (linea: \"+str(fila_token_actual)+\", posicion: \"+str(columna_token_actual)+\")\"+\"\\n\")\n",
        "\n",
        "\n",
        "#Impresion del resultado del analisis lexico\n",
        "print(solucion[0:-1])#se imprime sin el ultimo salto de linea que sobra usando substring"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-26fd2bdc85d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nPtSDbbY-R7",
        "outputId": "2dbea4a5-1243-4b17-ad14-5b31c98a6e59"
      },
      "source": [
        "es_palabra_reservada(\"si\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URaB6diPC8Lx",
        "outputId": "f5926d04-612e-44be-b1bb-2317a8d3ba3b"
      },
      "source": [
        "print(\"a\\rb\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\rb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1ARxWozhKkF",
        "outputId": "84021224-89ac-4ade-e1ed-216e4d4a0919"
      },
      "source": [
        "i=10\n",
        "devolver_buffer()\n",
        "devolver_buffer()\n",
        "i\n",
        "\n",
        "\n",
        "  if ( i>=2 and (not (regreso_1 or regreso_2)) ):\n",
        "    #Ajuste regresos en el buffer\n",
        "    caracter_leido_regresar_1 = T[i-1]\n",
        "    if (caracter_leido_regresar_1 ==\"\\n\"):\n",
        "      fila_actual_regresar_1 += 1\n",
        "      columna_actual_regresar_1 = 1\n",
        "    else:\n",
        "      columna_actual_regresar_1 +=1 \n",
        "\n",
        "    caracter_leido_regresar_2 = T[i-2]\n",
        "    if (caracter_leido_regresar_2 ==\"\\n\"):\n",
        "      fila_actual_regresar_2 += 1\n",
        "      columna_actual_regresar_2 = 1\n",
        "    else:\n",
        "      columna_actual_regresar_2 +=1\n",
        "  elif (regreso_1):\n",
        "    fila_actual = fila_actual_regresar_1\n",
        "    columna_actual = columna_actual_regresar_1\n",
        "  elif (regreso_2):\n",
        "    fila_actual = fila_actual_regresar_2\n",
        "    columna_actual = columna_actual_regresar_2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfLD6t4_QOYn"
      },
      "source": [
        "simbolos = {\n",
        "  '+',\n",
        "  '-',\n",
        "  '*',\n",
        "  '/',\n",
        "  '%',\n",
        "  '=',\n",
        "  '<',\n",
        "  '>',\n",
        "  '<=',\n",
        "  '>=',\n",
        "  '==',\n",
        "  '&&',\n",
        "  '||',\n",
        "  '!=',\n",
        "  '!',\n",
        "  ':',\n",
        "  ';',\n",
        "  ',',\n",
        "  '.',\n",
        "  '(',\n",
        "  ')'\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}