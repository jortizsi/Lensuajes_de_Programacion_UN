{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica_2_LP_analizador_sintactico.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "emeUzg-_qDlT"
      },
      "source": [
        "# ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ \n",
        "#|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|\n",
        "                                                                                                                               \n",
        "                                                                                                                              \n",
        "\n",
        "#_____________________________\n",
        "\n",
        "modo_debuggeo = False\n",
        "entrada_pruebas = \"\"\"\n",
        "funcion_principal\n",
        "  b = \"uwu\";\n",
        "fin_principal\n",
        "\"\"\"\n",
        "\n",
        "#Obtener y unificar input\n",
        "import sys\n",
        "T =\"\"\n",
        "\n",
        "if (not modo_debuggeo):\n",
        "  for line in sys.stdin:\n",
        "    T += line\n",
        "else:\n",
        "  for line in entrada_pruebas:\n",
        "    T += line\n",
        "\n",
        "\n",
        "#algunos tokens requieren leer un caracter adelante. Se agrega un espacio\n",
        "#para que esto siempre sea posible\n",
        "#las cadenas y carcteres no requieren esto\n",
        "l = len(T)\n",
        "if (l>=1 and not (T[-1] in (\"'\",'\"')) and (l>=2 and not (T[-2] in (\"'\",'\"')))):\n",
        "  T += \" \"\n",
        "\n",
        "\n",
        "#string para el outut\n",
        "#solucion = \"\"\n",
        "#_____________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  ___              _ _              _              _               _           \n",
        " / _ \\            | (_)            | |            | |      /      (_)          \n",
        "/ /_\\ \\_ __   __ _| |_ ______ _  __| | ___  _ __  | |     _____  ___  ___ ___  \n",
        "|  _  | '_ \\ / _` | | |_  / _` |/ _` |/ _ \\| '__| | |    / _ \\ \\/ / |/ __/ _ \\ \n",
        "| | | | | | | (_| | | |/ / (_| | (_| | (_) | |    | |___|  __/>  <| | (_| (_) |\n",
        "\\_| |_/_| |_|\\__,_|_|_/___\\__,_|\\__,_|\\___/|_|    \\_____/\\___/_/\\_\\_|\\___\\___/ \n",
        "\n",
        "  Aqui se ubica el analizador lexico de la practica anterior modificado para que ahora ofrezca la funcion siguiente token \n",
        "                                                                               \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#Diccionario usado para el metodo toStrig de un objeto Token\n",
        "diccionario_simbolos = {\n",
        "  '+':\"tk_mas\",\n",
        "  '-':\"tk_menos\",\n",
        "  '*':\"tk_mult\",\n",
        "  '/':\"tk_div\",\n",
        "  '%':\"tk_mod\",\n",
        "  '=':\"tk_asig\",\n",
        "  '<':\"tk_menor\",\n",
        "  '>':\"tk_mayor\",\n",
        "  '<=': \"tk_menor_igual\",\n",
        "  '>=':\"tk_mayor_igual\",\n",
        "  '==': \"tk_igual\",\n",
        "  '&&':\"tk_y\",\n",
        "  '||':\"tk_o\",\n",
        "  '!=':\"tk_dif\",\n",
        "  '!':\"tk_neg\",\n",
        "  ':':\"tk_dosp\",\n",
        "  ';':\"tk_pyc\",\n",
        "  ',':\"tk_coma\",\n",
        "  '.':\"tk_punto\",\n",
        "  '(':\"tk_par_izq\",\n",
        "  ')':\"tk_par_der\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Lista de palabras reservadas del lenguaje para redoulucin implicita respecto a id's\n",
        "palabras_reservadas = (\"funcion_principal\", \"fin_principal\", \n",
        "                        \"booleano\", \"caracter\", \"entero\", \"real\", \"cadena\",\n",
        "                        \"verdadero\",\"falso\", \n",
        "                        \"leer\", \"imprimir\",\n",
        "                        \"si\",\"entonces\", \"si_no\", \"fin_si\",\n",
        "                        \"mientras\", \"hacer\", \"fin_mientras\",\n",
        "                        \"para\", \"fin_para\",\n",
        "                        \"seleccionar\", \"entre\", \"caso\", \"romper\", \"defecto\", \"fin_seleccionar\",\n",
        "                        \"estructura\", \"fin_estructura\",\n",
        "                        \"funcion\", \"retornar\", \"fin_funcion\")\n",
        "\n",
        "\n",
        "#funcion para revisar si una palabra es palabra reservada del lenguaje\n",
        "def es_palabra_reservada(token):\n",
        "  if(token in palabras_reservadas):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_______________________________________________________________________________________________________\n",
        "#Clase Token\n",
        "class Token(object):\n",
        "\n",
        "  #Constructor de la clase \n",
        "  def __init__(self, fila, columna, lexema, tipo): \n",
        "        self.__dict__.update(fila=fila, columna=columna, lexema=lexema, tipo=tipo) \n",
        "\n",
        "    \n",
        "  #Metodo to String que ayuda a imprimir cada token como se pide en el problema\n",
        "  def __str__(self):\n",
        "  \n",
        "    if (self.tipo in [12]):#ID'S\n",
        "      if (es_palabra_reservada(self.lexema)):\n",
        "        #<palabra_reservada,línea,columna>\n",
        "        pr = \"<\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "        return pr\n",
        "      else:\n",
        "        #<id,lexema,fila,columna>\n",
        "        pr = \"<id,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "        return pr\n",
        "    elif (self.tipo in [2,6]):\n",
        "      #<tk_entero,lexema,fila,columna>\n",
        "      pr = \"<tk_entero,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [5]):\n",
        "      #<tk_real,lexema,fila,columna>\n",
        "      pr = \"<tk_real,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [23]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      pr = \"<tk_caracter,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [32]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      pr = \"<tk_cadena,\"+self.lexema +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    elif (self.tipo in [41,51,71,882,83,92,93,102,103,202,302,402,403,501,601,701,801,901,1001,2002,3001, 64,82]):#Simbolos-operadores\n",
        "      #<token,fila,columna>\n",
        "      pr = \"<\"+ diccionario_simbolos[self.lexema] +\",\"+ str(self.fila)+\",\"+ str(self.columna)+\">\"\n",
        "      return pr\n",
        "    else:\n",
        "      return f'Lexema:{self.lexema} Fila: {self.fila} Columna: {self.columna} Tipo: {self.tipo}'\n",
        "\n",
        "\n",
        "  def imprimir_atributos(self):\n",
        "     print( f'Lexema:{self.lexema} Fila: {self.fila} Columna: {self.columna} Tipo: {self.tipo}')\n",
        "\n",
        "\n",
        "      #++++\n",
        "\n",
        "  def pasar_tipo_de_numero_a_cadena(self):\n",
        "\n",
        "    \n",
        "  \n",
        "    if (self.tipo in [12]):#ID'S\n",
        "      if (es_palabra_reservada(self.lexema)):\n",
        "        #<palabra_reservada,línea,columna>\n",
        "        self.tipo = self.lexema\n",
        "        \n",
        "      else:\n",
        "        #<id,lexema,fila,columna>\n",
        "        self.tipo = \"id\"\n",
        "        \n",
        "    elif (self.tipo in [2,6]):\n",
        "      #<tk_entero,lexema,fila,columna>\n",
        "      self.tipo = \"tk_entero\"\n",
        "      \n",
        "    elif (self.tipo in [5]):\n",
        "      #<tk_real,lexema,fila,columna>\n",
        "      self.tipo = \"tk_real\"\n",
        "      \n",
        "    elif (self.tipo in [23]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      self.tipo = \"tk_caracter\"\n",
        "      \n",
        "    elif (self.tipo in [32]):\n",
        "      #<tk_caracter,lexema,fila,columna>\n",
        "      self.tipo = \"tk_cadena\"\n",
        "      \n",
        "    elif (self.tipo in [41,51,71,882,83,92,93,102,103,202,302,402,403,501,601,701,801,901,1001,2002,3001, 64,82]):#Simbolos-operadores\n",
        "      #<token,fila,columna>\n",
        "      self.tipo = diccionario_simbolos[self.lexema]\n",
        "      \n",
        "    else:\n",
        "      self.tipo = \"tipo desconocido\"\n",
        "#_______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_______________________________________________________________________________________________________\n",
        "#Listas utiles\n",
        "digitos = ['0','1','2','3','4','5','6','7','8','9']\n",
        "letras = ['a','e', 'i', 'o', 'u', 'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z']\n",
        "LETRAS = ['A','E', 'I', 'O', 'U', 'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z']\n",
        "caracteres = digitos + letras + LETRAS +[' ','_','\\n']\n",
        "caracteres_permitidos_ids = digitos + letras + LETRAS +['_']\n",
        "alfabeto = letras + LETRAS\n",
        "estados_de_aceptacion = [2,5,6,12,23,32,41,51,71,82,83,92,93,102,103,202,302,402,403,501,601,701,801,901,1001,2002,65,67,64,3001]\n",
        "\n",
        "#variables para verificar que no aparezcan comillassimples o dobles sin cierre\n",
        "comillas_simples_cerradas = 0 \n",
        "comillas_dobles_cerradas = 0\n",
        "#_______________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#_________________________________________________________________________________\n",
        "#Funcion de trancision asociada al DT para analisis lexico\n",
        "def Funcion_de_transicion(estado, caracter_leido):\n",
        "  global lexema_actual\n",
        "  global comillas_simples_cerradas\n",
        "  global comillas_dobles_cerradas\n",
        "\n",
        "  if (estado==0):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 1\n",
        "    elif (caracter_leido in alfabeto): #Toda variable inicia por letra\n",
        "      return 11\n",
        "    elif (caracter_leido == \"'\"):\n",
        "      comillas_simples_cerradas += 1\n",
        "      return 21\n",
        "    elif (caracter_leido == '\"'):\n",
        "      comillas_dobles_cerradas += 1\n",
        "      return 31\n",
        "    elif (caracter_leido == \"+\"):\n",
        "      return 41\n",
        "    elif (caracter_leido == \"-\"):\n",
        "      return 51\n",
        "    elif (caracter_leido == \"/\"):\n",
        "      return 61\n",
        "    elif (caracter_leido == \"%\"):\n",
        "      return 71\n",
        "    elif (caracter_leido == \"=\"):\n",
        "      return 81\n",
        "    elif (caracter_leido == \"<\"):\n",
        "      return 91\n",
        "    elif (caracter_leido == \">\"):\n",
        "      return 101\n",
        "    elif (caracter_leido == \"&\"):\n",
        "      return 201\n",
        "    elif (caracter_leido == \"|\"):\n",
        "      return 301\n",
        "    elif (caracter_leido == \"!\"):\n",
        "      return 401\n",
        "    elif (caracter_leido == \":\"):\n",
        "      return 501\n",
        "    elif (caracter_leido == \";\"):\n",
        "      return 601\n",
        "    elif (caracter_leido == \",\"):\n",
        "      return 701\n",
        "    elif (caracter_leido == \".\"):\n",
        "      return 801\n",
        "    elif (caracter_leido == \"(\"):\n",
        "      return 901\n",
        "    elif (caracter_leido == \")\"):\n",
        "      return 1001\n",
        "    elif (caracter_leido == \"*\"):\n",
        "      return 3001\n",
        "    elif (caracter_leido in [' ', '\\n', '\\r', '\\t'] ):\n",
        "      lexema_actual.pop(-1)\n",
        "      return 0\n",
        "\n",
        "\n",
        "\n",
        "  if (estado==1):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 1\n",
        "    elif (caracter_leido == '.'):\n",
        "      return 3\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 2\n",
        "\n",
        "  if (estado==2):\n",
        "    #devolver_buffer()\n",
        "    #print(\"estado 2 devolvio buffer\",i)\n",
        "    return 0\n",
        "\n",
        "  if (estado==3):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 4\n",
        "    else:\n",
        "      devolver_buffer_2()\n",
        "      return 6\n",
        "\n",
        "  if (estado==4):\n",
        "    if (caracter_leido in digitos):\n",
        "      return 4\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 5\n",
        "\n",
        "  if (estado==5):\n",
        "    return 0\n",
        "\n",
        "  if (estado==6):\n",
        "    return 0\n",
        "\n",
        "  #ID's\n",
        "  if (estado==11):\n",
        "    if (caracter_leido in caracteres_permitidos_ids):\n",
        "      return 11\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 12\n",
        "\n",
        "  if (estado==12):\n",
        "    return 0\n",
        "\n",
        "  #CARACTER\n",
        "  if (estado==21):\n",
        "    if (caracter_leido in caracteres):\n",
        "      return 22\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==22):\n",
        "    if (caracter_leido == \"'\"):\n",
        "      comillas_simples_cerradas -= 1\n",
        "      return 23\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==23):\n",
        "    return 0\n",
        "\n",
        "\n",
        "  #CADENA\n",
        "  if (estado==31):\n",
        "    if (caracter_leido in caracteres):\n",
        "      return 31\n",
        "    if (caracter_leido == '\"'):\n",
        "      comillas_dobles_cerradas -= 1\n",
        "      return 32\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  if (estado==32):\n",
        "    return 0\n",
        "\n",
        "  # +\n",
        "  if (estado==41):\n",
        "    return 0\n",
        "\n",
        "  # -\n",
        "  if (estado==51):\n",
        "    return 0\n",
        "\n",
        "  # %\n",
        "  if (estado==71):\n",
        "    return 0\n",
        "\n",
        "  # =\n",
        "  if (estado==81):\n",
        "    if (caracter_leido == '='):\n",
        "      return 82\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 83\n",
        "  \n",
        "  # < y <=\n",
        "  if (estado==91):\n",
        "    if (caracter_leido == '='):\n",
        "      return 92\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 93\n",
        "\n",
        "  # > y >=\n",
        "  if (estado==101):\n",
        "    if (caracter_leido == '='):\n",
        "      return 102\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 103\n",
        "\n",
        "  # &&\n",
        "  if (estado==201):\n",
        "    if (caracter_leido == '&'):\n",
        "      return 202\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  # ||\n",
        "  if (estado==301):\n",
        "    if (caracter_leido == '|'):\n",
        "      return 302\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  # !=\n",
        "  if (estado==401):\n",
        "    if (caracter_leido == '='):\n",
        "      return 402\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 403\n",
        "  \n",
        "\n",
        "  #Demas simbolos\n",
        "  if (estado in [501,601,701,801,901,1001,3001,202,302,402]):\n",
        "    return 0\n",
        "\n",
        "  # / --> comentarios y division\n",
        "  if (estado==61):\n",
        "    if (caracter_leido == '/'):\n",
        "      return 62\n",
        "    elif (caracter_leido == '*'):\n",
        "      return 63\n",
        "    else:\n",
        "      devolver_buffer_1()\n",
        "      return 64\n",
        "\n",
        "  \n",
        "  # // comentario una linea\n",
        "  if (estado==62):\n",
        "    if (caracter_leido != '\\n'):\n",
        "      return 62\n",
        "    else:\n",
        "      return 65\n",
        "\n",
        "\n",
        "  # /* comentario multilinea\n",
        "  if (estado==63):\n",
        "    if (caracter_leido != '*'):\n",
        "      return 63\n",
        "    else:\n",
        "      return 66\n",
        "\n",
        "  \n",
        "  if (estado==66):\n",
        "    if (caracter_leido != '/'):\n",
        "      return 63\n",
        "    else:\n",
        "      return 67\n",
        "\n",
        "  if (estado in [65,67,64]):\n",
        "    return 0\n",
        "\n",
        "  return -1\n",
        "#_________________________________________________________________________________\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "  \n",
        "#_________________________________________________________________________\n",
        "#buffer donde van poniendose simbolos a se analizados\n",
        "buffer = []\n",
        "\n",
        "\n",
        "#variables para llevar la posicion y guardar lugar de iniio de tokens\n",
        "fila_actual = 1\n",
        "columna_actual = 1\n",
        "\n",
        "fila_token_actual = 1\n",
        "columna_token_actual =1\n",
        "\n",
        "estado = 0\n",
        "regreso_realizado = False\n",
        "#_________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#____________________________________________\n",
        "#pila para llevar el lexema actual\n",
        "lexema_actual = [] \n",
        "l = len(T)\n",
        "\n",
        "#funcion para obtener string del lexema\n",
        "def obtener_lexema(s):\n",
        "  respuesta = \"\"\n",
        "  for i in s:\n",
        "    respuesta += str(i)\n",
        "  return respuesta\n",
        "#____________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#____________________________________________\n",
        "#Metodos para devolver el buffer n estados\n",
        "#con sus respectivos ajustes\n",
        "\n",
        "i = 0\n",
        "Lista_posiciones = []\n",
        "\n",
        "def devolver_buffer_1():\n",
        "  global regreso_realizado\n",
        "  regreso_realizado = True\n",
        "  #print(\"buffer atras 1\")\n",
        "  global i \n",
        "  i = i-1\n",
        "  global lexema_actual\n",
        "  lexema_actual.pop(-1)\n",
        "  Lista_posiciones.pop(-1)\n",
        "  posicion = Lista_posiciones[-1]\n",
        "  fila_actual = posicion[0]\n",
        "  columna_actual = posicion[1]\n",
        "\n",
        "def devolver_buffer_2():\n",
        "  global regreso_realizado\n",
        "  regreso_realizado = True\n",
        "  #print(\"buffer atras 2\")\n",
        "  global i \n",
        "  i = i-2\n",
        "  global lexema_actual\n",
        "  lexema_actual.pop(-1)\n",
        "  lexema_actual.pop(-1)\n",
        "  global fila_actual\n",
        "  global columna_actual\n",
        "  Lista_posiciones.pop(-1)\n",
        "  Lista_posiciones.pop(-1)\n",
        "  posicion = Lista_posiciones[-1]\n",
        "  fila_actual = posicion[0]\n",
        "  columna_actual = posicion[1]\n",
        "#____________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "buffer.append(T[0]) #Agregar caracter inicial para el analizador lexico\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Funcion para obtener el siguiente token\n",
        "\n",
        "def siguiente_token():\n",
        "  global buffer\n",
        "  global lexema_actual\n",
        "  global fila_actual\n",
        "  global columna_actual\n",
        "  global Lista_posiciones\n",
        "  global estado\n",
        "  global i\n",
        "  global regreso_realizado\n",
        "  global fila_token_actual\n",
        "  global columna_token_actual\n",
        "  token_a_retornar = []\n",
        "  token_a_retornar_ya_hallado = False\n",
        "\n",
        "  while (len(buffer) > 0):\n",
        "\n",
        "    if (token_a_retornar_ya_hallado):\n",
        "      return token_a_retornar\n",
        "\n",
        "    #inicio de un token\n",
        "    if (lexema_actual == []):\n",
        "      fila_token_actual = fila_actual\n",
        "      columna_token_actual = columna_actual\n",
        "\n",
        "\n",
        "    #leer caracter\n",
        "    caracter_leido = buffer.pop(0)\n",
        "    lexema_actual += caracter_leido\n",
        "    #Guardar posicion por si mas adelante hay retorno del buffer\n",
        "    posicion_actual = [[fila_actual, columna_actual]]\n",
        "    Lista_posiciones += posicion_actual\n",
        "    \n",
        "\n",
        "    #cambiar de estado\n",
        "    regreso_realizado = False\n",
        "    estado = Funcion_de_transicion(estado, caracter_leido)\n",
        "    if (estado == -1):\n",
        "      print(\">>> 1Error lexico (linea: \"+str(fila_actual)+\", posicion: \"+str(columna_actual)+\")\"+\"\\n\")\n",
        "      break\n",
        "\n",
        "\n",
        "\n",
        "    #Si se llego a un estado de aceptacion guardar el token hallado. Los estados de comentarios se ignoran.\n",
        "    if (estado in estados_de_aceptacion):\n",
        "      Token_actual_objeto = Token(fila_token_actual, columna_token_actual, obtener_lexema(lexema_actual), estado )\n",
        "      if (estado not in [67,65]):\n",
        "        #solucion += (str(Token_actual_objeto) + \"\\n\")\n",
        "        #print(Token_actual_objeto)\n",
        "        token_a_retornar = Token_actual_objeto\n",
        "        token_a_retornar.pasar_tipo_de_numero_a_cadena()\n",
        "        token_a_retornar_ya_hallado = True\n",
        "      lexema_actual = [] #reiniciar lexema\n",
        "      estado = 0 #Transicion lambda al estado 0 \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Obtener siguiente caracter a usar en el DT\n",
        "    #En caso de haberse dado retorno del buffer, la i fue ajustada en las funciones buffer\n",
        "    i += 1\n",
        "    if (i<l):\n",
        "      buffer.append(T[i])\n",
        "\n",
        "    #Actualizar fila y columna del siguiente caracter a leer\n",
        "    #En caso de haberse dado retorno del buffer, la posicion fue ajustada en las funciones buffer\n",
        "    if (not (regreso_realizado)):\n",
        "      if (caracter_leido==\"\\n\"):\n",
        "        fila_actual +=1\n",
        "        columna_actual = 1\n",
        "      else:\n",
        "        columna_actual +=1  \n",
        "\n",
        "  #Si se hallo comilla simple o doble sin cierre y no existe un error lexico antes generar error\n",
        "  #Esta situacion solo hace referencia al final de la entrada porque el DT se ocupa de los demas casos adecuadamente\n",
        "  if ((comillas_dobles_cerradas + comillas_simples_cerradas) != 0  and estado != -1):\n",
        "    print(\">>> 2Error lexico (linea: \"+str(fila_token_actual)+\", posicion: \"+str(columna_token_actual)+\")\"+\"\\n\")\n",
        "\n",
        "  return Token(fila_token_actual, columna_token_actual, \"EOF\", \"EOF\" )\n",
        "  #Impresion del resultado del analisis lexico\n",
        "  #print(solucion[0:-1])#se imprime sin el ultimo salto de linea que sobra usando substring\n",
        "\n",
        "#entero a = 1\n",
        "#st = siguiente_token()\n",
        "#st.imprimir_atributos()\n",
        "#print(siguiente_token())\n",
        "#print(st)\n",
        "\n",
        "# ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ \n",
        "#|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ \n",
        "#|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|\n",
        "\n",
        "\"\"\"\n",
        "  ___              _ _              _                  _       _             _   _           \n",
        " / _ \\            | (_)            | |                (_)     | |   /       | | (_)          \n",
        "/ /_\\ \\_ __   __ _| |_ ______ _  __| | ___  _ __   ___ _ _ __ | |_ __ _  ___| |_ _  ___ ___  \n",
        "|  _  | '_ \\ / _` | | |_  / _` |/ _` |/ _ \\| '__| / __| | '_ \\| __/ _` |/ __| __| |/ __/ _ \\ \n",
        "| | | | | | | (_| | | |/ / (_| | (_| | (_) | |    \\__ \\ | | | | || (_| | (__| |_| | (_| (_) |\n",
        "\\_| |_/_| |_|\\__,_|_|_/___\\__,_|\\__,_|\\___/|_|    |___/_|_| |_|\\__\\__,_|\\___|\\__|_|\\___\\___/ \n",
        "\n",
        "  Aqui se desarrolla un analizador sintatico para psicoder, en forma de un ASDR.\n",
        "  Se han automatizado la gran mayoria de aspectos. Es posible cambiar facilmente la gramatica usada. Por convencion los no terminales deben ser mayusculas.\n",
        "  La logica de este programa opera ampliamente bajo el uso de listas. \n",
        "                                                                                             \n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "# DICCIONARIOS UTILES\n",
        "\n",
        "\n",
        "diccionario_simbolos_y_tokens = {\n",
        "  \"tk_mas\":\"+\",\n",
        "  \"tk_menos\":\"-\",\n",
        "  \"tk_mult\":\"*\",\n",
        "  \"tk_div\":\"/\",\n",
        "  \"tk_mod\":\"%\",\n",
        "  \"tk_asig\":\"=\",\n",
        "  \"tk_menor\":\"<\",\n",
        "  \"tk_mayor\":\">\",\n",
        "  \"tk_menor_igual\":\"<=\",\n",
        "  \"tk_mayor_igual\":\">=\",\n",
        "  \"tk_igual\":\"==\",\n",
        "  \"tk_y\":\"&&\",\n",
        "  \"tk_o\":\"||\",\n",
        "  \"tk_dif\":\"!=\",\n",
        "  \"tk_neg\":\"!\",\n",
        "  \"tk_dosp\":\":\",\n",
        "  \"tk_pyc\":\";\",\n",
        "  \"tk_coma\":\",\",\n",
        "  \"tk_punto\":\".\",\n",
        "  \"tk_par_izq\":\"(\",\n",
        "  \"tk_par_der\":\")\",\n",
        "  \"id\":\"identificador\",\n",
        "  \"tk_entero\":\"valor_entero\",\n",
        "  \"tk_real\":\"valor_real\",\n",
        "  \"tk_caracter\":\"valor_caracter\",\n",
        "  \"tk_cadena\":\"valor_cadena\",\n",
        "  \"funcion_principal\":\"funcion_principal\",\n",
        "  \"fin_principal\":\"fin_principal\",\n",
        "  \"leer\":\"leer\",\n",
        "  \"imprimir\":\"imprimir\",\n",
        "  \"booleano\":\"booleano\",\n",
        "  \"caracter\":\"caracter\",\n",
        "  \"entero\":\"entero\",\n",
        "  \"real\":\"real\",\n",
        "  \"cadena\":\"cadena\",\n",
        "  \"si\":\"si\",\n",
        "  \"entonces\":\"entonces\",\n",
        "  \"fin_si\":\"fin_si\",\n",
        "  \"si_no\":\"si_no\",\n",
        "  \"mientras\":\"mientras\",\n",
        "  \"hacer\":\"hacer\",\n",
        "  \"fin_mientras\":\"fin_mientras\",\n",
        "  \"para\":\"para\",\n",
        "  \"fin_para\":\"fin_para\",\n",
        "  \"seleccionar\":\"seleccionar\",\n",
        "  \"entre\":\"entre\",\n",
        "  \"caso\":\"caso\",\n",
        "  \"romper\":\"romper\",\n",
        "  \"defecto\":\"defecto\",\n",
        "  \"fin_seleccionar\":\"fin_seleccionar\",\n",
        "  \"estructura\":\"estructura\",\n",
        "  \"fin_estructura\":\"fin_estructura\",\n",
        "  \"funcion\":\"funcion\",\n",
        "  \"fin_funcion\":\"fin_funcion\",\n",
        "  \"retornar\":\"retornar\",\n",
        "  \"falso\":\"falso\",\n",
        "  \"verdadero\":\"verdadero\",\n",
        "  \"EOF\":\"EOF\"\n",
        "}\n",
        "\n",
        "diccionario_prioridad_errores = {\n",
        "  \"tk_mas\":0,\n",
        "  \"tk_menos\":1,\n",
        "  \"tk_mult\":2,\n",
        "  \"tk_div\":3,\n",
        "  \"tk_mod\":4,\n",
        "  \"tk_asig\":5,\n",
        "  \"tk_menor\":6,\n",
        "  \"tk_mayor\":7,\n",
        "  \"tk_menor_igual\":8,\n",
        "  \"tk_mayor_igual\":9,\n",
        "  \"tk_igual\":10,\n",
        "  \"tk_y\":11,\n",
        "  \"tk_o\":12,\n",
        "  \"tk_dif\":13,\n",
        "  \"tk_neg\":14,\n",
        "  \"tk_dosp\":15,\n",
        "  \"tk_pyc\":16,\n",
        "  \"tk_coma\":17,\n",
        "  \"tk_punto\":18,\n",
        "  \"tk_par_izq\":19,\n",
        "  \"tk_par_der\":20,\n",
        "  \"id\":21,\n",
        "  \"tk_entero\":22,\n",
        "  \"tk_real\":23,\n",
        "  \"tk_caracter\":24,\n",
        "  \"tk_cadena\":25,\n",
        "  \"funcion_principal\":26,\n",
        "  \"fin_principal\":27,\n",
        "  \"leer\":28,\n",
        "  \"imprimir\":29,\n",
        "  \"booleano\":30,\n",
        "  \"caracter\":31,\n",
        "  \"entero\":32,\n",
        "  \"real\":33,\n",
        "  \"cadena\":34,\n",
        "  \"si\":35,\n",
        "  \"entonces\":36,\n",
        "  \"fin_si\":37,\n",
        "  \"si_no\":38,\n",
        "  \"mientras\":39,\n",
        "  \"hacer\":40,\n",
        "  \"fin_mientras\":41,\n",
        "  \"para\":42,\n",
        "  \"fin_para\":43,\n",
        "  \"seleccionar\":44,\n",
        "  \"entre\":45,\n",
        "  \"caso\":46,\n",
        "  \"romper\":47,\n",
        "  \"defecto\":48,\n",
        "  \"fin_seleccionar\":49,\n",
        "  \"estructura\":50,\n",
        "  \"fin_estructura\":51,\n",
        "  \"funcion\":52,\n",
        "  \"fin_funcion\":53,\n",
        "  \"retornar\":54,\n",
        "  \"falso\":55,\n",
        "  \"verdadero\":56,\n",
        "  \"EOF\":57\n",
        "}\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " _____                                      _     _                \n",
        "|  __ \\                               /    | |   (_)               \n",
        "| |  \\/  _ __    __ _   _ __ ___     __ _  | |_   _    ___    __ _ \n",
        "| | __  | '__|  / _` | | '_ ` _ \\   / _` | | __| | |  / __|  / _` |\n",
        "| |_\\ \\ | |    | (_| | | | | | | | | (_| | | |_  | | | (__  | (_| |\n",
        " \\____/ |_|     \\__,_| |_| |_| |_|  \\__,_|  \\__| |_|  \\___|  \\__,_|\n",
        "\n",
        "    \n",
        "    Aqui debe definirse la gramatica a utilizar en el analizador sintactico.  \n",
        "    Una gramatica en la representacion aqui usada se define como una lista de reglas\n",
        "    teniendo cada regla dos elementos que son el lado izquierdo y el lado derecho de la regla. \n",
        "\n",
        "    La gramatica usada por el analizador  es aquella cuyo nombre es \"gramatica\".\n",
        "\n",
        "    Como el ASDR esta completamente automatizado, si se quiere cambiar la gramatica con la que trabaja el analizador\n",
        "    no es necesario modificar funciones, lo unico que debe hacerse es cambiar el contenido de la variable \"gramatica\".     \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "#gramatica basica para testeo\n",
        "gramatica1 = [\n",
        "                      #Equivalencia en notacion formal\n",
        " [\"A\",['a','b','c']], # A --> a b c\n",
        " [\"A\",['u','v','w']], # A --> u v w\n",
        " [\"B\",[\"A\",'x','y']]  # A --> A x y\n",
        "\n",
        " ]\n",
        "\n",
        "#Gramatica ejemplo vista en clase para testeo\n",
        "gramatica2 = [\n",
        " \n",
        " [\"A\",[\"B\", \"C\"]],\n",
        " [\"A\",['ant','A','all']],\n",
        "\n",
        " [\"B\",[\"big\",'C']],\n",
        " [\"B\",[\"bus\",'A',\"boss\"]],\n",
        " [\"B\",['Ɛ']],\n",
        " [\"C\",[\"cat\"]],\n",
        " [\"C\",[\"cow\"]]\n",
        "\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_lectura = [ \n",
        "  #guardar el valor leido en una variable\n",
        "  [\"LECTURA\",[\"leer\",\"tk_par_izq\",\"id\",\"ATRIBUTO_O_VARIABLE\"]],\n",
        "  [\"ATRIBUTO_O_VARIABLE\",[\"tk_par_der\",\"tk_pyc\"]],\n",
        "  #guardar el vaalor leido como atributo de un objeto\n",
        "  [\"ATRIBUTO_O_VARIABLE\",[\"tk_punto\",\"id\",\"OTROS_GETS\",\"tk_par_der\",\"tk_pyc\"]],\n",
        "  [\"OTROS_GETS\",[\"tk_punto\",\"id\",\"OTROS_GETS\"]],\n",
        "  [\"OTROS_GETS\",['Ɛ']],\n",
        "  ]\n",
        "\n",
        "subgramatica_impresion = [ \n",
        "  [\"IMPRESION\",[\"imprimir\",\"tk_par_izq\",\"PARAMETROS_IMPRESION\",\"tk_par_der\",\"tk_pyc\"]],\n",
        "  [\"PARAMETROS_IMPRESION\",[\"PARAMETRO_IMPRESION\",\"PARAMETROS_IMPRESION_2_A_N\"]],\n",
        "  [\"PARAMETROS_IMPRESION_2_A_N\",[\"tk_coma\",\"PARAMETRO_IMPRESION\",\"PARAMETROS_IMPRESION_2_A_N\"]],\n",
        "  [\"PARAMETROS_IMPRESION_2_A_N\",['Ɛ']],\n",
        "\n",
        "  #[\"PARAMETRO_IMPRESION\",[\"id\"]],\n",
        "  #[\"PARAMETRO_IMPRESION\",[\"DATO\"]],\n",
        "  [\"PARAMETRO_IMPRESION\",[\"EXPRESION\"]]\n",
        "  \n",
        "  ]\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_expresiones = [ \n",
        " #[\"TEST\",[\"EXPRESION\",\"tk_par_der\"]],\n",
        "\n",
        " [\"EXPRESION_ENTRE_PARENTESIS\",['tk_par_izq',\"EXPRESION\",\"tk_par_der\"]],\n",
        "\n",
        " [\"EXPRESION\",[\"POSIBLE_NEGACION_O_CAMBIO_DE_SIGNO\",\"ELEMENTO_PARA_OPERACION\", \"EXPRESION_2_A_N\"]],\n",
        " [\"EXPRESION_2_A_N\",[\"OPERACION\",\"POSIBLE_NEGACION_O_CAMBIO_DE_SIGNO\",\"ELEMENTO_PARA_OPERACION\", \"EXPRESION_2_A_N\"]],\n",
        " [\"EXPRESION_2_A_N\",['Ɛ']],\n",
        " \n",
        "\n",
        " [\"ELEMENTO_PARA_OPERACION\",['DATO']],\n",
        " [\"ELEMENTO_PARA_OPERACION\",[\"id\",'POSIBLE_FUNCION']],\n",
        " ['POSIBLE_FUNCION',[\"LLAMADA_A_FUNCION\"]],\n",
        " ['POSIBLE_FUNCION',['Ɛ']],\n",
        " ['POSIBLE_FUNCION',['tk_punto',\"id\",\"OTROS_GETS\"]],#acceso a valor de un atributo\n",
        " [\"ELEMENTO_PARA_OPERACION\",[\"EXPRESION_ENTRE_PARENTESIS\"]],\n",
        "\n",
        "\n",
        " [\"POSIBLE_NEGACION_O_CAMBIO_DE_SIGNO\",[\"tk_neg\"]],\n",
        " [\"POSIBLE_NEGACION_O_CAMBIO_DE_SIGNO\",[\"tk_menos\"]],\n",
        " [\"POSIBLE_NEGACION_O_CAMBIO_DE_SIGNO\",['Ɛ']],\n",
        " \n",
        "\n",
        " [\"OPERACION\",[\"tk_mas\"]],\n",
        " [\"OPERACION\",[\"tk_menos\"]],\n",
        " [\"OPERACION\",[\"tk_mult\"]],\n",
        " [\"OPERACION\",[\"tk_div\"]],\n",
        " [\"OPERACION\",[\"tk_mod\"]],\n",
        " [\"OPERACION\",[\"tk_menor\"]],\n",
        " [\"OPERACION\",[\"tk_mayor\"]],\n",
        " [\"OPERACION\",[\"tk_menor_igual\"]],\n",
        " [\"OPERACION\",[\"tk_mayor_igual\"]],\n",
        " [\"OPERACION\",[\"tk_igual\"]],\n",
        " [\"OPERACION\",[\"tk_dif\"]],\n",
        " [\"OPERACION\",[\"tk_o\"]],\n",
        " [\"OPERACION\",[\"tk_y\"]],\n",
        " [\"SOLVE\",[\"EXPRESION_SIN_PARENTESIS\",\";\"]]\n",
        "                              \n",
        "]\n",
        "\n",
        "subgramatica_instancias_dato = [\n",
        "  [\"DATO\",['verdadero']], \n",
        "  [\"DATO\",['falso']],     \n",
        "  [\"DATO\",['tk_caracter']], \n",
        "  [\"DATO\",['tk_entero']],   \n",
        "  [\"DATO\",['tk_real']], \n",
        "  [\"DATO\",['tk_cadena']]   \n",
        "                              \n",
        "]\n",
        "\n",
        "subgramatica_tipos_de_dato = [\n",
        "  [\"TIPO\",['booleano']],      \n",
        "  [\"TIPO\",['caracter']], \n",
        "  [\"TIPO\",['entero']],   \n",
        "  [\"TIPO\",['real']], \n",
        "  [\"TIPO\",['cadena']],\n",
        " # [\"TIPO\",['id']] #El nombre una estructura es usado en declaraciones <Objeto nombre_instancia>;     \n",
        "                              \n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_estructuras = [ \n",
        " [\"ESTRUCTURA\",[\"estructura\",'id',\"ATRIBUTOS\",\"fin_estructura\"]],\n",
        " [\"ATRIBUTOS\",[\"DECLARACIONES_1_A_N\"]],\n",
        " [\"DECLARACIONES_1_A_N\",[\"DECLARACION\",\"DECLARACIONES_1_A_N\"]],#atributos tipo datos primitivos\n",
        " [\"DECLARACIONES_1_A_N\",[\"DECLARACION_INSTANCIA_OBJETO\",\"DECLARACIONES_1_A_N\"]],#atributos tipo objeto\n",
        " [\"DECLARACIONES_1_A_N\",['Ɛ']],\n",
        " [\"ATRIBUTOS\",['Ɛ']],\n",
        " [\"DECLARACION_INSTANCIA_OBJETO\",[\"id\",\"id\",\"tk_pyc\"]],\n",
        "\n",
        " ]\n",
        "\n",
        "#declaracion de una o mas variables, por ejemplo entero a,b,c;\n",
        "subgramatica_creacion_variables = [\n",
        " [\"DECLARACION\",[\"TIPO\",\"id\",\"INICIALIZACION_VARIABLE\",\"VARIABLES_2_A_N\",\"tk_pyc\"]],\n",
        " [\"VARIABLES_2_A_N\",[\"tk_coma\",\"id\",\"INICIALIZACION_VARIABLE\",\"VARIABLES_2_A_N\"]],\n",
        " [\"VARIABLES_2_A_N\",['Ɛ']],\n",
        " [\"INICIALIZACION_VARIABLE\",['tk_asig',\"EXPRESION\"]], #antes estaba dato\n",
        " [\"INICIALIZACION_VARIABLE\",['Ɛ']]                    \n",
        "\n",
        " ]\n",
        "\n",
        "\n",
        "subgramatica_asignacion = [\n",
        " #[\"VARIABLE_O_LLAMADA_A_FUNCION\",[\"id\",\"VARIABLE_O_LLAMADA_A_FUNCION\"]],\n",
        " #[\"VARIABLE_O_LLAMADA_A_FUNCION\",[\"ASIGNACION\"]],\n",
        " #[\"VARIABLE_O_LLAMADA_A_FUNCION\",[\"LLAMADA_A_FUNCION\"]],\n",
        "\n",
        " [\"ASIGNACION\",[\"tk_asig\",\"ASIGNACION_DESPUES_DEL_IGUAL\"]],\n",
        " [\"ASIGNACION_DESPUES_DEL_IGUAL\",[\"EXPRESION\",\"tk_pyc\"]],\n",
        " #[\"ASIGNACION_DESPUES_DEL_IGUAL\",[\"id\",\"LLAMADA_A_FUNCION\",\"tk_pyc\"]]                    \n",
        " ]\n",
        "\n",
        "#ID ID ID \n",
        "#Los ids pueden ser llamadas a funciones, asignaciones o creacion de objetos\n",
        "#id()\n",
        "#id=x\n",
        "#id id;\n",
        "\n",
        "subgramatica_gestor_de_ids = [\n",
        "  [\"GESTOR_ID\",[\"id\",\"VARIABLE_O_OBJETO_O_FUNCION\"]],\n",
        "  [\"VARIABLE_O_OBJETO_O_FUNCION\",[\"id\",\"tk_pyc\"]], #instanciacion de objeto\n",
        "  [\"VARIABLE_O_OBJETO_O_FUNCION\",[\"ASIGNACION\"]], #asignacion de valor a variable\n",
        "  [\"VARIABLE_O_OBJETO_O_FUNCION\",[\"LLAMADA_A_FUNCION\",\"tk_pyc\"]],   #llamada a funcion\n",
        "  [\"VARIABLE_O_OBJETO_O_FUNCION\",[\"tk_punto\",\"id\",\"OTROS_GETS\",\"ASIGNACION\"]]  #Asignar el valor de un atributo en un objeto \n",
        "  #[\"OTROS_GETS\",[\"tk_punto\",\"id\",\"OTROS_GETS\"]],\n",
        "  #[\"OTROS_GETS\",['Ɛ']],                      \n",
        "]\n",
        "\n",
        "\n",
        "subgramatica_funciones = [\n",
        " \n",
        " [\"FUNCION\",[\"funcion\",\"TIPO_SALIDA_FUNCION\",\"id\",\"tk_par_izq\",\"PARAMETROS_FUNCION\",\"tk_par_der\",\"hacer\",\"ACCIONES_CUERPO_FUNCION\",\"retornar\",\"EXPRESION\",\"tk_pyc\",\"fin_funcion\"]],\n",
        " [\"PARAMETROS_FUNCION\",[\"TIPO_SALIDA_FUNCION\", \"id\",\"PARAMETROS_FUNCION_2_A_N\"]],\n",
        " [\"PARAMETROS_FUNCION\",['Ɛ']],\n",
        " [\"PARAMETROS_FUNCION_2_A_N\",['Ɛ']],\n",
        " [\"PARAMETROS_FUNCION_2_A_N\",[\"tk_coma\",\"TIPO_SALIDA_FUNCION\", \"id\",\"PARAMETROS_FUNCION_2_A_N\"]],\n",
        " [\"PARAMETROS_FUNCION_2_A_N\",['Ɛ']],\n",
        "\n",
        " [\"LLAMADA_A_FUNCION\",[\"tk_par_izq\",\"PARAMETROS_LLAMADA_A_FUNCION\",\"tk_par_der\"]],\n",
        " [\"PARAMETROS_LLAMADA_A_FUNCION\",[\"PARAMETRO_LLAMADA_A_FUNCION\", \"PARAMETROS_LLAMADA_A_FUNCION_2_A_N\"]],\n",
        " [\"PARAMETROS_LLAMADA_A_FUNCION_2_A_N\",[\"tk_coma\",\"PARAMETRO_LLAMADA_A_FUNCION\", \"PARAMETROS_LLAMADA_A_FUNCION_2_A_N\"]],\n",
        " [\"PARAMETROS_LLAMADA_A_FUNCION\",['Ɛ']],\n",
        " [\"PARAMETRO_LLAMADA_A_FUNCION\",[\"DATO\"]],\n",
        " [\"PARAMETRO_LLAMADA_A_FUNCION\",[\"id\"]],\n",
        " [\"PARAMETROS_LLAMADA_A_FUNCION_2_A_N\",['Ɛ']],\n",
        "\n",
        "  [\"ACCIONES_CUERPO_FUNCION\",[\"ACCION\",\"ACCIONES_CUERPO_FUNCION\"]],\n",
        "  [\"ACCIONES_CUERPO_FUNCION\",['Ɛ']],\n",
        "  [\"TIPO_SALIDA_FUNCION\",[\"TIPO\"]],\n",
        "  [\"TIPO_SALIDA_FUNCION\",[\"id\"]],\n",
        "\n",
        "\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_condicional = [\n",
        " [\"CONDICIONAL\",[\"si\",\"tk_par_izq\",\"EXPRESION\",\"tk_par_der\",\"entonces\",\"ACCIONES_CONDICIONAL\",\"ALTERNATIVA\",\"fin_si\"]],\n",
        " [\"ALTERNATIVA\",['si_no',\"ACCIONES_CONDICIONAL\"]],\n",
        " [\"ALTERNATIVA\",['Ɛ']],\n",
        "\n",
        " #[\"ACCIONES_CONDICIONAL\",[\"ACCION\",\"ACCIONES_2_A_N\"]],  \n",
        " #[\"ACCIONES_CONDICIONAL_2_A_N\",[\"ACCION\",\"ACCIONES_2_A_N\"]],\n",
        " #[\"ACCIONES_2_A_N\",['Ɛ']],\n",
        " [\"ACCIONES_CONDICIONAL\",[\"ACCION\",\"ACCIONES_CONDICIONAL\"]],  \n",
        " #[\"ACCIONES_CONDICIONAL_2_A_N\",[\"ACCION\",\"ACCIONES_2_A_N\"]],\n",
        " [\"ACCIONES_CONDICIONAL\",['Ɛ']],\n",
        "\n",
        " [\"ACCION\",[\"GESTOR_ID\"]],  \n",
        " [\"ACCION\",[\"IMPRESION\"]],\n",
        " [\"ACCION\",[\"LECTURA\"]], \n",
        " [\"ACCION\",[\"IMPRESION\"]], \n",
        "\n",
        " [\"ACCION\",[\"DECLARACION\"]], \n",
        " [\"ACCION\",[\"CONDICIONAL\"]], \n",
        " [\"ACCION\",[\"CICLO_PARA\"]], \n",
        " [\"ACCION\",[\"CICLO_HACER_MIENTRAS\"]],\n",
        " [\"ACCION\",[\"CICLO_MIENTRAS\"]],\n",
        " [\"ACCION\",[\"COMANDO_SELECCION\"]],\n",
        " [\"ACCION\",[\"romper\",\"tk_pyc\"]] # break de frenar ejecucion de una funcion o ciclo         \n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_ciclo_para = [\n",
        " [\"CICLO_PARA\",[\"para\",\"tk_par_izq\",\"INICIALIZACION_CICLO_PARA\",\"tk_pyc\",\"EXPRESION\",\"tk_pyc\",\"PASO\",\"tk_par_der\",\"hacer\",\"ACCIONES_CICLO_PARA\",\"fin_para\"]],\n",
        " [\"INICIALIZACION_CICLO_PARA\",[\"entero\",\"id\",\"tk_asig\",\"tk_entero\"]],\n",
        " [\"INICIALIZACION_CICLO_PARA\",[\"id\",\"tk_asig\",\"tk_entero\"]],\n",
        " [\"PASO\",['id']],\n",
        " [\"PASO\",['tk_entero']],\n",
        " [\"ACCIONES_CICLO_PARA\",[\"ACCION\",\"ACCIONES_CICLO_PARA\"]],\n",
        " [\"ACCIONES_CICLO_PARA\",['Ɛ']]   \n",
        " #[\"ACCION\",[\"ASIGNACION\"]] \n",
        "               \n",
        " ]\n",
        "\n",
        "\n",
        "subgramatica_ciclo_mientras = [\n",
        " [\"CICLO_MIENTRAS\",[\"mientras\",\"tk_par_izq\",\"EXPRESION\",\"tk_par_der\",\"hacer\",\"ACCIONES_MIENTRAS\",\"fin_mientras\"]],\n",
        " [\"INICIALIZACION_CICLO_PARA\",[\"entero\",\"id\",\"tk_asig\",\"tk_entero\"]],\n",
        " [\"INICIALIZACION_CICLO_PARA\",[\"id\",\"tk_asig\",\"tk_entero\"]],\n",
        " [\"PASO\",['id']],\n",
        " [\"PASO\",['tk_entero']],\n",
        " [\"ACCIONES_MIENTRAS\",[\"ACCION\",\"ACCIONES_MIENTRAS\"]],\n",
        " [\"ACCIONES_MIENTRAS\",['Ɛ']]\n",
        "               \n",
        " ]\n",
        "\n",
        "\n",
        "subgramatica_ciclo_hacer_mientras = [\n",
        " #[\"CICLO_HACER_MIENTRAS\",[\"hacer\",\"ACCIONES_HACER_MIENTRAS\",\"mientras\",\"tk_par_izq\",\"EXPRESION\",\"tk_par_der\",\"tk_pyc\"]],\n",
        " [\"CICLO_HACER_MIENTRAS\",[\"hacer\",\"ACCIONES_HACER_MIENTRAS\",\"CLAUSULA_MIENTRAS\"]],\n",
        " [\"ACCIONES_HACER_MIENTRAS\",[\"ACCION_CHM\",\"ACCIONES_HACER_MIENTRAS\"]],\n",
        " [\"ACCIONES_HACER_MIENTRAS\",['Ɛ']],\n",
        "\n",
        " [\"CLAUSULA_MIENTRAS\",[\"mientras\",\"tk_par_izq\",\"EXPRESION\",\"tk_par_der\",\"INICIO_CM_ANIDADO_O_FIN_CHM\"]],\n",
        " [\"INICIO_CM_ANIDADO_O_FIN_CHM\",[\"hacer\",\"ACCIONES_MIENTRAS\",\"fin_mientras\",\"ACCIONES_HACER_MIENTRAS\",\"CLAUSULA_MIENTRAS\"]],\n",
        " #[\"CLAUSULA_MIENTRAS_CICLO_MIENTRAS_O_CIERRE_HACER_MIENTRAS\",[\";\"]],\n",
        " [\"INICIO_CM_ANIDADO_O_FIN_CHM\",['tk_pyc']],\n",
        "\n",
        " [\"ACCION_CHM\",[\"GESTOR_ID\"]],  \n",
        " [\"ACCION_CHM\",[\"IMPRESION\"]],\n",
        " [\"ACCION_CHM\",[\"LECTURA\"]], \n",
        "\n",
        " [\"ACCION_CHM\",[\"DECLARACION\"]], \n",
        " [\"ACCION_CHM\",[\"CONDICIONAL\"]], \n",
        " [\"ACCION_CHM\",[\"CICLO_PARA\"]], \n",
        " [\"ACCION_CHM\",[\"CICLO_HACER_MIENTRAS\"]],\n",
        " [\"ACCION_CHM\",[\"COMANDO_SELECCION\"]],\n",
        " [\"ACCION_CHM\",[\"romper\",\"tk_pyc\"]]\n",
        " #[\"ACCION_CHM\",[\"CLAUSULA_MIENTRAS\"]]\n",
        "#[\"ACCIONES_HACER_MIENTRAS\",[\"ACCION\",\"ACCIONES_HACER_MIENTRAS_2_A_N\"]],\n",
        " #[\"ACCIONES_HACER_MIENTRAS_2_A_N\",[\"ACCION\",\"ACCIONES_HACER_MIENTRAS_2_A_N\"]],\n",
        " #[\"ACCIONES_HACER_MIENTRAS_2_A_N\",['Ɛ']]                \n",
        " ]\n",
        "\n",
        "\n",
        "subgramatica_comando_seleccion = [\n",
        " [\"COMANDO_SELECCION\",[\"seleccionar\",\"tk_par_izq\",\"id\",\"tk_par_der\",\"entre\",\"CASOS\",\"fin_seleccionar\"]],\n",
        "\n",
        " [\"CASOS\",['CASO_DEFECTO']],\n",
        " [\"CASO_DEFECTO\",[\"defecto\",\"tk_dosp\",\"ACCIONES_COMANDO_SELECCION\",\"ROMPIMIENTO\"]],#PERMITIR ACCIONES VACIAS\n",
        "\n",
        " [\"CASOS\",['UNO_O_MAS_CASOS']],\n",
        " [\"UNO_O_MAS_CASOS\",['caso',\"tk_entero\",\"tk_dosp\",\"ACCIONES_COMANDO_SELECCION\",\"ROMPIMIENTO\",\"CASOS_2_A_N\"]],\n",
        " [\"CASOS_2_A_N\",['caso',\"tk_entero\",\"tk_dosp\",\"ACCIONES_COMANDO_SELECCION\",\"ROMPIMIENTO\",\"CASOS_2_A_N\"]],\n",
        " [\"CASOS_2_A_N\",['Ɛ']],\n",
        " [\"CASOS_2_A_N\",['CASO_DEFECTO']],\n",
        "\n",
        " [\"ROMPIMIENTO\",['romper',\"tk_pyc\"]],\n",
        " [\"ROMPIMIENTO\",['Ɛ']],\n",
        "\n",
        " [\"ACCIONES_COMANDO_SELECCION\",[\"ACCION_SELECCION\",\"ACCIONES_COMANDO_SELECCION\"]],\n",
        " [\"ACCIONES_COMANDO_SELECCION\",['Ɛ']],\n",
        " \n",
        " [\"ACCION_SELECCION\",[\"GESTOR_ID\"]],  \n",
        " [\"ACCION_SELECCION\",[\"IMPRESION\"]],\n",
        " [\"ACCION_SELECCION\",[\"LECTURA\"]], \n",
        " [\"ACCION_SELECCION\",[\"IMPRESION\"]], \n",
        "\n",
        " [\"ACCION_SELECCION\",[\"DECLARACION\"]], \n",
        " [\"ACCION_SELECCION\",[\"CONDICIONAL\"]], \n",
        " [\"ACCION_SELECCION\",[\"CICLO_PARA\"]], \n",
        " [\"ACCION_SELECCION\",[\"CICLO_HACER_MIENTRAS\"]],\n",
        " [\"ACCION_SELECCION\",[\"CICLO_MIENTRAS\"]],\n",
        " [\"ACCION_SELECCION\",[\"COMANDO_SELECCION\"]]\n",
        "        \n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "subgramatica_estructura_y_funciones = [\n",
        " \n",
        "  [\"ESTRUCTURAS_Y_FUNCIONES\",[\"ESTRUCTURA_O_FUNCION\"]],\n",
        "  [\"ESTRUCTURA_O_FUNCION\",[\"ESTRUCTURA\",\"ESTRUCTURA_O_FUNCION\"]],\n",
        "  [\"ESTRUCTURA_O_FUNCION\",[\"FUNCION\",\"ESTRUCTURA_O_FUNCION\"]],\n",
        "  [\"ESTRUCTURA_O_FUNCION\",['Ɛ']]\n",
        "        \n",
        " ]\n",
        "\n",
        "\n",
        "subgramatica_funcion_principal = [\n",
        " \n",
        "  [\"FUNCION_PRINCIPAL\",[\"funcion_principal\",\"ACCIONES_FUNCION_PRINCIPAL\",\"fin_principal\"]],\n",
        "  [\"ACCIONES_FUNCION_PRINCIPAL\",[\"ACCION\",\"ACCIONES_FUNCION_PRINCIPAL\"]],\n",
        "  [\"ACCIONES_FUNCION_PRINCIPAL\",['Ɛ']],\n",
        "        \n",
        " ]\n",
        "\n",
        "\n",
        "regla_inicial = [\n",
        " \n",
        " [\"PROGRAMA_EN_PSICODER\",[\"ESTRUCTURAS_Y_FUNCIONES\",\"FUNCION_PRINCIPAL\",\"ESTRUCTURAS_Y_FUNCIONES\",\"EOF\"]]\n",
        "        \n",
        " ]\n",
        "\n",
        "\n",
        "#GRAMATICA USADA POR EL ANALIZADOR SINTACTICO\n",
        "gramatica = subgramatica_lectura + subgramatica_estructuras + subgramatica_creacion_variables + subgramatica_tipos_de_dato + subgramatica_instancias_dato\n",
        "gramatica += subgramatica_expresiones + subgramatica_impresion + subgramatica_funciones + subgramatica_asignacion + subgramatica_condicional\n",
        "gramatica += subgramatica_gestor_de_ids + subgramatica_ciclo_para + subgramatica_ciclo_mientras + subgramatica_ciclo_hacer_mientras + subgramatica_comando_seleccion\n",
        "gramatica += subgramatica_estructura_y_funciones + regla_inicial + subgramatica_funcion_principal \n",
        "gramatica3 = [\n",
        " \n",
        " [\"A\",['entero',\"B\"]],\n",
        " [\"B\",['id',\"C\",\"y\"]],\n",
        " [\"C\",[\"tk_asig\",\"D\"]],\n",
        " [\"D\",['tk_entero']]\n",
        "\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "#FUNCIONES AUXILIARES\n",
        "\n",
        "\n",
        "\n",
        "#metodo para borrar caracter vacio o epsilon\n",
        "def quitar_epsilon(lista_entrada):\n",
        "  lista_respuesta = lista_entrada.copy()\n",
        "  repeticiones = lista_respuesta.count('Ɛ')\n",
        "  for i in range (repeticiones):\n",
        "    lista_respuesta.remove('Ɛ')\n",
        "  return lista_respuesta\n",
        "\n",
        "\n",
        "\n",
        "#Hallar una lista con los posibles lados derechos de reglas dado un simbolo no terminal\n",
        "def hallar_reglas_aplicables(no_terminal):\n",
        "  respuesta = []\n",
        "  for i in gramatica:\n",
        "    if (i[0] == no_terminal):\n",
        "      respuesta.append(i[1])\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "\n",
        "#Verificar si el simbolo es terminal mediante convencion de que los no terminales usan mayusculas\n",
        "def es_terminal(termino):\n",
        "  return termino.islower() or (termino == 'Ɛ') or (termino in [\"VERDADERO\",\"FALSO\",\"EOF\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#funcion para obtener indices donde aparece un no terminal dado el lado derecho de una regla\n",
        "def encontar_indices(lista, elemento_buscado):\n",
        "  respuesta = []\n",
        "  l = len(lista)\n",
        "  for i in range(l):\n",
        "    if (lista[i] == elemento_buscado):\n",
        "      respuesta.append(i)\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "\n",
        "#Obtener todas las reglas en cuyo lado derecho aparezca un determinado no terminal\n",
        "def hallar_reglas_donde_aparece(no_terminal):\n",
        "  respuesta = []\n",
        "  for i in gramatica:\n",
        "    if (i[0] != no_terminal and no_terminal in i[1]):  #i[1] indica lado derecho de la regla\n",
        "      respuesta.append(i)\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "\n",
        "#funcion para obtener los sufijos que aparecen despues de un no terminal dado, en el lado derecho de una regla\n",
        "#se empaca junto al simbolo que genera la regla.\n",
        "def obtener_betas(nt_izquierda, regla, NO_TERMINAL):\n",
        "  derecha_regla = regla[1]\n",
        "  respuesta = []\n",
        "  ultimo_beta_no_vacio = len(derecha_regla)-2\n",
        "  indices_del_no_terminal = encontar_indices(derecha_regla, NO_TERMINAL)\n",
        "\n",
        "  for indice in indices_del_no_terminal:\n",
        "    if (indice <= ultimo_beta_no_vacio):\n",
        "      respuesta.append([nt_izquierda, derecha_regla[(indice+1):]])\n",
        "    else:\n",
        "      respuesta.append([nt_izquierda,'Ɛ'])\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\"\"\"\n",
        "____________ ________  ___ ___________ _____ _____ \n",
        "| ___ \\ ___ \\_   _|  \\/  ||  ___| ___ \\  _  /  ___|\n",
        "| |_/ / |_/ / | | | .  . || |__ | |_/ / | | \\ `--. \n",
        "|  __/|    /  | | | |\\/| ||  __||    /| | | |`--. \\\n",
        "| |   | |\\ \\ _| |_| |  | || |___| |\\ \\\\ \\_/ /\\__/ /\n",
        "\\_|   \\_| \\_|\\___/\\_|  |_/\\____/\\_| \\_|\\___/\\____/ \n",
        "                                                   \n",
        "\"\"\"\n",
        "\n",
        "#Implementacion del metodo primeros(a)\n",
        "def PRIMEROS(a):\n",
        "\n",
        "  solucion = []\n",
        "  n = len(a)\n",
        "\n",
        "  #Si la entrada es el caracter vacio la salida es una lista con un elemento caracter vacio\n",
        "  if (a == 'Ɛ'):\n",
        "    return ['Ɛ']\n",
        "\n",
        "  #si la entrada es un terminal la salida es ella misma\n",
        "  elif (es_terminal(a[0])):\n",
        "    return [a[0]]\n",
        "\n",
        "  else:\n",
        "\n",
        "    #obtener todos los lados derechos que se pueden obtener usando el no terminal a0\n",
        "    reglas_aplicables = hallar_reglas_aplicables(a[0])\n",
        "\n",
        "    #determinar todos los elementos primeros que se puden agregar en virtud de a0\n",
        "    primeros_de_a0 = []\n",
        "    for regla_i in reglas_aplicables:\n",
        "      primeros_de_a0_i = PRIMEROS(regla_i) #elementos tomados de usar la regla i\n",
        "      primeros_de_a0 += primeros_de_a0_i #actualizar elementos totales que surgen del no terminal a0\n",
        "\n",
        "    #Agregar elementos diferentes a epsilon\n",
        "    solucion += quitar_epsilon(primeros_de_a0)\n",
        "\n",
        "    #Aplicar las consideraciones de casos donde hay un epsilon\n",
        "    if ('Ɛ' in primeros_de_a0):\n",
        "      if (n==1):\n",
        "        solucion += ['Ɛ'] #Si no hay nada despues de a0 y a0 es epsilon, agregar epsilon\n",
        "      elif (n>1):\n",
        "        lista_sin_primer_elemento = a[1:]\n",
        "        solucion += PRIMEROS(lista_sin_primer_elemento) #si existen simbolos despues de a0 y a0 es epsilon, permitir contenido de a1 dentro de primeros de a\n",
        "\n",
        "    return solucion\n",
        "    \n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\"\"\"\n",
        " _____ _____ _____ _   _ _____ _____ _   _ _____ _____ _____ \n",
        "/  ___|_   _|  __ \\ | | |_   _|  ___| \\ | |_   _|  ___/  ___|\n",
        "\\ `--.  | | | |  \\/ | | | | | | |__ |  \\| | | | | |__ \\ `--. \n",
        " `--. \\ | | | | __| | | | | | |  __|| . ` | | | |  __| `--. \\\n",
        "/\\__/ /_| |_| |_\\ \\ |_| |_| |_| |___| |\\  | | | | |___/\\__/ /\n",
        "\\____/ \\___/ \\____/\\___/ \\___/\\____/\\_| \\_/ \\_/ \\____/\\____/ \n",
        "                                                             \n",
        "\"\"\"\n",
        "\n",
        "      \n",
        "#Implementacion del metodo siguientes(A)\n",
        "\n",
        "def SIGUIENTES (NO_TERMINAL):\n",
        "\n",
        "  solucion = []\n",
        "  if (NO_TERMINAL == \"A\"):\n",
        "    solucion += \"$\"\n",
        "\n",
        "  #obtener todos los lados derechos donde es posible encontrar el no terminal\n",
        "  reglas_donde_aparece = hallar_reglas_donde_aparece(NO_TERMINAL) \n",
        "\n",
        "  #determinar todos los β que son los sufijos que siguen al no terminal en alguna regla\n",
        "  #cada beta es un par 'simbolo lado izquierdo'/'lista del contenido en el lado derecho'\n",
        "  βetas = []\n",
        "  for regla in reglas_donde_aparece:\n",
        "    no_terminal_izq_regla = regla[0]\n",
        "    βetas_regla_i = obtener_betas(no_terminal_izq_regla,regla, NO_TERMINAL)\n",
        "    βetas += βetas_regla_i\n",
        "\n",
        "  #Obtener los elementos que se obtienen al procesar los sufijos beta. \n",
        "  #En caso de hallar un epsilon debe realizarse siguiente(S) para el simbolo S\n",
        "  #que estando en la izquierda permite obtener un epsilon.\n",
        "\n",
        "  for β in βetas:\n",
        "    contenido_beta = β[1]\n",
        "    primeros_de_beta = PRIMEROS(contenido_beta)\n",
        "    if ( ('Ɛ' in primeros_de_beta) or (β == 'Ɛ') ):\n",
        "      simbolo_lado_izquierdo = β[0]\n",
        "      solucion += SIGUIENTES(simbolo_lado_izquierdo)\n",
        "\n",
        "    primeros_no_vacios_de_beta = quitar_epsilon(primeros_de_beta)\n",
        "    solucion += primeros_no_vacios_de_beta\n",
        "\n",
        "  return list(dict.fromkeys(solucion)) #retornar eliminando repeticiones si las hay\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\"\"\"\n",
        "______             _ _          _             \n",
        "| ___ \\           | (_)        (_)  /          \n",
        "| |_/ / __ ___  __| |_  ___ ___ _  ___  _ __  \n",
        "|  __/ '__/ _ \\/ _` | |/ __/ __| |/ _ \\| '_ \\ \n",
        "| |  | | |  __/ (_| | | (_| (__| | (_) | | | |\n",
        "\\_|  |_|  \\___|\\__,_|_|\\___\\___|_|\\___/|_| |_|\n",
        "                                              \n",
        "\"\"\"\n",
        "\n",
        "#Implementacion de la funcion de prediccion\n",
        "#cada registro tiene la forma regla, prediccion \n",
        "#cada regla es un par lado izquierdo, lado derecho\n",
        "\n",
        "\n",
        "#Calcula todos los conjuntos de prediccion.\n",
        "def TODAS_LAS_PREDICCIONES():\n",
        "  solucion = []\n",
        "  for regla_i in gramatica:\n",
        "\n",
        "    simbolo_no_terminal = regla_i[0]\n",
        "    lado_dercho_de_la_regla = regla_i[1]\n",
        "\n",
        "    primeros_regla_i_derecha = PRIMEROS(lado_dercho_de_la_regla)\n",
        "    if ('Ɛ' in primeros_regla_i_derecha):\n",
        "      solucion.append([regla_i, quitar_epsilon(primeros_regla_i_derecha) + SIGUIENTES(simbolo_no_terminal)])\n",
        "    else:\n",
        "      solucion.append([regla_i, primeros_regla_i_derecha])\n",
        "\n",
        "  return solucion\n",
        "\n",
        "\n",
        "\n",
        "#Calcula todos los conjuntos de prediccion respecto las reglas con un simbolo S en el lado izquierdo\n",
        "def PRED(S):\n",
        "  solucion = []\n",
        "  for regla_i in gramatica:\n",
        "\n",
        "    simbolo_no_terminal = regla_i[0]\n",
        "    lado_dercho_de_la_regla = regla_i[1]\n",
        "\n",
        "    if (simbolo_no_terminal == S):\n",
        "\n",
        "      primeros_regla_i_derecha = PRIMEROS(lado_dercho_de_la_regla)\n",
        "      if ('Ɛ' in primeros_regla_i_derecha):\n",
        "        solucion.append([regla_i, quitar_epsilon(primeros_regla_i_derecha) + SIGUIENTES(simbolo_no_terminal)])\n",
        "      else:\n",
        "        solucion.append([regla_i, primeros_regla_i_derecha])\n",
        "\n",
        "  return solucion\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\"\"\"\n",
        "  ___    _____  ______  ______ \n",
        " / _ \\  /  ___| |  _  \\ | ___ \\\n",
        "/ /_\\ \\ \\ `--.  | | | | | |_/ /\n",
        "|  _  |  `--. \\ | | | | |    / \n",
        "| | | | /\\__/ / | |/ /  | |\\ \\ \n",
        "\\_| |_/ \\____/  |___/   \\_| \\_|\n",
        "                               \n",
        "\"\"\"\n",
        "\n",
        "#Implementacion del ASDR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dar_formato_token_esperado(token_esperado):\n",
        "  respuesta= '\"' + diccionario_simbolos_y_tokens[token_esperado] + '\"'#Convertir el token al formato de impresion de errores.Guardarlo.\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "#CASO INCONSISTENCIA EN TOKEN ESPERADO Y LEIDO\n",
        "#Metodo para imprimir un error al emparejar un token con un terminal\n",
        "def imprimir_error(token_esperado):\n",
        "  if (token_esperado == \"funcion_principal\"): \n",
        "    print(\"Error sintactico: falta funcion_principal\",end='')\n",
        "  else:\n",
        "    print(f'<{token.fila},{token.columna}> Error sintactico: se encontro: \"{token.lexema}\"; se esperaba: {dar_formato_token_esperado(token_esperado)}.',end='')\n",
        "\n",
        "\n",
        "\n",
        "#Implementacion del metodo emparejar visto en clase\n",
        "def emparejar(token_esperado):\n",
        "  global token\n",
        "  global PARAR\n",
        "  global modo_debuggeo\n",
        "  if (modo_debuggeo):\n",
        "    print(\"emparejando \", \" token actual: \",token.tipo,' esperado: \"', token_esperado,'\"') #Descomentar para ver mejor el proceso\n",
        "  if (token.tipo == token_esperado):\n",
        "    token = siguiente_token()\n",
        "    if (modo_debuggeo):\n",
        "      print(\"siguiente token: \",token) #Descomentar para ver mejor el proceso \n",
        "  else:\n",
        "    imprimir_error(token_esperado)\n",
        "    PARAR = True\n",
        "\n",
        "\n",
        "#CASO DONDO NO HAY REGLAS APLICABLES GENERANDO ERROR\n",
        "#Metodo para ordenar y modificar los tokens esperados, segun la convencion dada, en casos donde se imprimen errores\n",
        "def dar_formato_opciones_esperadas(lista):\n",
        "  respuesta = ['Ɛ']*58 #lista de 58 epsilons. Cada epsilon puede ser reemplazado o no por algun token esperado.\n",
        "  for i in lista:\n",
        "    indice = diccionario_prioridad_errores[i] #Hallar prioridad del token\n",
        "    respuesta[indice] = '\"' + diccionario_simbolos_y_tokens[i] + '\"'#Convertir el token al formato de impresion de errores.Guardarlo.\n",
        "  respuesta = quitar_epsilon(respuesta) #eliminar indices con epsilon\n",
        "  respuesta = \", \".join(respuesta) #separar los tokens por coma y espacio\n",
        "  return respuesta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "#FUNCION PARA PROCESAR UN NO TERMINAL S\n",
        "  #Inicializacion: Obtener las reglas y predicciones asociadas para casos con el no terminal S a la izquierda\n",
        "  #1. Obtener regla a aplicar\n",
        "  #2. Utilizar regla seleccionada \n",
        "\n",
        "\n",
        "PARAR = False #variable global usada para detener la ejecucucion de la funcion tras hallar un primer error\n",
        "\n",
        "def auto_funcion_para_no_terminal(S):\n",
        "  global modo_debuggeo\n",
        "  global PARAR\n",
        "  global token #el token a usar es una variable global que puede definirse y cambiarse en otras secciones fuera de esta funcion\n",
        "\n",
        "  #Obtener conjunto de reglas y sus predicciones para el simbolo S\n",
        "  reglas_y_predicciones_sobre_s = PRED(S)\n",
        "\n",
        "\n",
        "  #1.\n",
        "  #Revisamos las predicciones de S una por una hasta hallar la prediccion adecuada para el elemento que se quiere consumir.\n",
        "  #Una vez hecho esto guardamos la regla asociada.\n",
        "  regla_a_aplicar = \"indeterminado\"\n",
        "  opciones_esperadas = []\n",
        "  for reglas_y_predicciones_i in reglas_y_predicciones_sobre_s:\n",
        "    regla = reglas_y_predicciones_i[0][1] #0 indica tomar la regla y 1 tomar el lado derecho de la regla\n",
        "    prediccion = reglas_y_predicciones_i[1]\n",
        "    opciones_esperadas += prediccion #Tener lista de opciones esperadas en caso de error, para imprimirlas\n",
        "    if (token.tipo in prediccion):\n",
        "      regla_a_aplicar = regla\n",
        "      if (modo_debuggeo):\n",
        "        print(\"regla aplicable: \",  reglas_y_predicciones_i[0]) #Descomentar para ver mejor el proceso\n",
        "      break\n",
        "  \n",
        "\n",
        "  #Si ninguna regla aplica generar error\n",
        "  if (regla_a_aplicar == \"indeterminado\"):\n",
        "    if (\"funcion_principal\" in opciones_esperadas): \n",
        "      print(\"Error sintactico: falta funcion_principal\",end='')\n",
        "    else:\n",
        "      print(f'<{token.fila},{token.columna}> Error sintactico: se encontro: \"{token.lexema}\"; se esperaba: {dar_formato_opciones_esperadas(opciones_esperadas)}.',end='')\n",
        "    PARAR = True\n",
        "  else:\n",
        "\n",
        "    #2. \n",
        "    #Procesar cada elemento de la regla seleccionada\n",
        "    for elemento in regla_a_aplicar:\n",
        "\n",
        "      if (PARAR == True):\n",
        "        break\n",
        "  \n",
        "      if (elemento != 'Ɛ'):    \n",
        "        if es_terminal(elemento):\n",
        "          emparejar(elemento)# si es terminal emparejarlo y consumirlo\n",
        "        else:\n",
        "          auto_funcion_para_no_terminal(elemento)# si es no terminal correr la funcion para esa no terminal\n",
        "\n",
        "#++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "#______________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#main\n",
        "token = siguiente_token() #Primer token\n",
        "auto_funcion_para_no_terminal(\"PROGRAMA_EN_PSICODER\") #simbolo inicial de la gramatica\n",
        "if ( PARAR == False):\n",
        "  print(\"El analisis sintactico ha finalizado exitosamente.\",end='')\n",
        "\n",
        "\n",
        "#if (token != \"EOF\"):\n",
        "#  print(\"error eof\")\n",
        "#else:\n",
        "#  print(\"exito\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ ______ \n",
        "#|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|______|"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}